{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDS5210-2020 Midterm\n",
    "\n",
    "In the midterm, you're going to focus on using the programming skills that you've developed so far to build a calculator for the Apache II scoring system for ICU Mortality.  \n",
    "* https://www.mdcalc.com/apache-ii-score#evidence\n",
    "* https://reference.medscape.com/calculator/apache-ii-scoring-system\n",
    "\n",
    "For the midterm, we'll be building a calculator for the Apache II score and then running that against a patient file that's available to you out on the internet.  This will be broken down into three main steps:\n",
    "1. Create your JSON file to encapsulate all of the calculation rules for Apache II\n",
    "2. Create functions to calculate the Apache II score using your JSON configuration\n",
    "3. Create a function to loop over the patients in a file on the internet and calculate Apach II scores for all of them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Creating a JSON Rules File\n",
    "\n",
    "Look at the rules for the Apache II scoring system on the pages above.  The first step in the midterm is to use those rules and create a JSON configuration file as described in the 2019 midterm video.  I've provided a starter file named `apache.json` to get you started.\n",
    "\n",
    "Inside that file, you'll find placeholders for all of the measures that go into the Apache II scoring model:\n",
    "* Organ Failure History\n",
    "* Age\n",
    "* Temperature\n",
    "* [pH](https://en.wikipedia.org/wiki/PH)\n",
    "* Heart rate\n",
    "* Respiratory rate\n",
    "* [Sodium](https://www.mayoclinic.org/diseases-conditions/hyponatremia/symptoms-causes/syc-20373711)\n",
    "* [Potassium](https://www.emedicinehealth.com/hyperkalemia/article_em.htm)\n",
    "* [Creatinine](https://www.medicalnewstoday.com/articles/322380)\n",
    "* [Hematocrit](https://labtestsonline.org/tests/hematocrit)\n",
    "* White Blood Count\n",
    "* [FiO2](https://www.ausmed.com/cpd/articles/oxygen-flow-rate-and-fio2)\n",
    "* [PaO2](https://www.verywellhealth.com/partial-pressure-of-oyxgen-pa02-914920)\n",
    "* [A-a gradient](https://www.ncbi.nlm.nih.gov/books/NBK545153/)\n",
    "\n",
    "\n",
    "You may need to create a sort of nested set of rules in some cases.  For instance, the rule for Creatinine says to use certain ranges and points in the case of Acute Renal Failure and a different set of points for Chronic Renal Failure.\n",
    "\n",
    "Similarly, the rule for FiO2 says to use PaO2 to calculate scores if the FiO2 is <50, and to use A-a Gradient if the PaO2 is >50.\n",
    "\n",
    "When you've created your `apache.json` file, make sure it's in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your JSON\n",
    "\n",
    "The assert() functions below should all run just fine.  If you want to change the names of any of the keys in the JSON I provided you, you may, but you'll also need to update this test code so that it doesn't fail.  Remember, your notebook should be able to run end-to-end before you submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('apache.json') as f:\n",
    "    rules = json.load(f)\n",
    "\n",
    "assert('Organ Failure History' in rules.keys())\n",
    "assert('Age' in rules.keys())\n",
    "assert('Temperature' in rules.keys())\n",
    "assert('pH' in rules.keys())\n",
    "assert('Heart Rate' in rules.keys())\n",
    "assert('Respiratory Rate' in rules.keys())\n",
    "assert('Sodium' in rules.keys())\n",
    "assert('Potassium' in rules.keys())\n",
    "assert('Creatinine' in rules.keys())\n",
    "assert('Hematocrit' in rules.keys())\n",
    "assert('White Blood Count' in rules.keys())\n",
    "assert('FiO2' in rules.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Functions to evaluate rules\n",
    "\n",
    "Write a series of functions, enough to satisfy all of the main criteria that we're using to calculate the Apache II score.  That list is the same as the assert statements above.\n",
    "\n",
    "* Each of your functions should be well documented.\n",
    "* Each function should have \"config_file\" as one of it's parameters.\n",
    "* Each function should return a numerical score value.\n",
    "* Similar to what we discussed in the review, if you can generalize some rules, do so.  You should **NOT** end up with one function for each input variable.  If you did that, you'd have a lot of repetative code.\n",
    "\n",
    "The Glasgow Coma Scale is simply a 1-to-1 score translation.  Simply add the Glasgow Coma Scale value.  So, you don't need to write a function for this. [Glasgow Coma Scale](https://www.cdc.gov/masstrauma/resources/gcs.pdf)\n",
    "\n",
    "**CORRECTION ADDED 2/29** - The Glasgow Coma Scale points should be calculated as `1 - Glasgow Coma Scale` rather than what I just stated above.  My preference would be that you do the calculation correctly, as per MDCalc, and then use the **corrected** scores files to compare against as noted in Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2A Organ Failure History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def organ_history_score(history, config_file):\n",
    "    \"\"\" str, str -> int\n",
    "    history_list: A list of strings that include various organ failure history this subject DOES have\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on the organ failure history in the history_list\n",
    "    and the scoring rules in the config_file.  For instance, if the subject had Nonoperative,\n",
    "    the history score would be 2, and the function should return 7.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = json.load(open(config_file))\n",
    "    organ_history_scores = config.get(\"Organ Failure History\")\n",
    "    \n",
    "    if history in  organ_history_scores:\n",
    "        history_score = organ_history_scores.get(history)\n",
    "\n",
    "    return history_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"apache.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( organ_history_score('Emergency', CONFIG_FILE) == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2B Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def age_score(age, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The age of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual age in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    age_rules = config.get(\"Age\")\n",
    "    \n",
    "    for rule in age_rules:\n",
    "        if age >= rule.get('min') and age < rule.get('max'):\n",
    "            age_score = rule.get('points')\n",
    "            \n",
    "    return age_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( age_score(30, CONFIG_FILE) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2C Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def temperature_score(temp, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    temp: The Temperature of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring \n",
    "    \n",
    "    The function should return a score for this subject based on where their actual temperature\n",
    "    in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    temp_rules = config.get(\"Temperature\")\n",
    "    \n",
    "    for rule in temp_rules:\n",
    "        if temp >= rule.get('min') and temp < rule.get('max'):\n",
    "            temperature_score = rule.get('points')\n",
    "            \n",
    "    return temperature_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( temperature_score(37, CONFIG_FILE) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2D pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def ph_score(ph, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The ph of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual pH in \n",
    "    the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    ph_rules = config.get(\"pH\")\n",
    "    \n",
    "    for rule in ph_rules:\n",
    "        if ph >= rule.get('min') and ph < rule.get('max'):\n",
    "            ph_score = rule.get('points')\n",
    "            \n",
    "    return ph_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( ph_score(6.5, CONFIG_FILE) == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2E Heart Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def hr_score(hr, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The heart rate of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual heart\n",
    "    rate in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    hr_rules = config.get(\"Heart Rate\")\n",
    "    \n",
    "    for rule in hr_rules:\n",
    "        if hr >= rule.get('min') and hr < rule.get('max'):\n",
    "            hr_score = rule.get('points')\n",
    "            \n",
    "    return hr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( hr_score(50, CONFIG_FILE) == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2F Respiratory Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def rr_score(rr, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The Respiratory Rate of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    Respiratory Rate in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    rr_rules = config.get(\"Respiratory Rate\")\n",
    "    \n",
    "    for rule in rr_rules:\n",
    "        if rr >= rule.get('min') and rr < rule.get('max'):\n",
    "            rr_score = rule.get('points')\n",
    "            \n",
    "    return rr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( rr_score(30, CONFIG_FILE) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2G Sodium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def sodium_score(sodium, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The Sodium of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring \n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    Sodium in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    sodium_rules = config.get(\"Sodium\")\n",
    "    \n",
    "    for rule in sodium_rules:\n",
    "        if sodium >= rule.get('min') and sodium < rule.get('max'):\n",
    "            sodium_score = rule.get('points')\n",
    "            \n",
    "    return sodium_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( sodium_score(100, CONFIG_FILE) == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2H Potassium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def potassium_score(potassium, config_file):\n",
    "    \"\"\" float, str -> int\n",
    "    age: The potassium of the subject is an float value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    Respiratory Rate in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    potassium_rules = config.get(\"Potassium\")\n",
    "    \n",
    "    for rule in potassium_rules:\n",
    "        if potassium >= rule.get('min') and potassium < rule.get('max'):\n",
    "            potassium_score = rule.get('points')\n",
    "            \n",
    "    return potassium_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( potassium_score(2.8, CONFIG_FILE) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2I Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def creatinine_score(failure_type, creatinine, config_file):\n",
    "    \"\"\" str, int, str -> int\n",
    "    age: The Hematocrit of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    Hematocrit in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    failure_rules = config.get(\"Creatinine\")\n",
    "    acute_rules = failure_rules.get(\"Acute Renal Failure\")\n",
    "    chronic_rules = failure_rules.get(\"Chronic Renal Failure\")\n",
    "    if failure_type == \"Acute Renal Failure\":\n",
    "        for rule1 in acute_rules:\n",
    "            if creatinine >= rule1.get('min') and creatinine < rule1.get('max'):\n",
    "                creatinine_score = rule1.get('points')\n",
    "    if failure_type == \"Chronic Renal Failure\":\n",
    "        for rule2 in chronic_rules:\n",
    "            if creatinine >= rule2.get('min') and creatinine < rule2.get('max'):\n",
    "                creatinine_score = rule2.get('points')\n",
    "            \n",
    "    return creatinine_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(creatinine_score(\"Acute Renal Failure\", 3, CONFIG_FILE) == 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2J Hematocrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def hematocrit_score(hema, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The Hematocrit of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    Hematocrit in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    hema_rules = config.get(\"Hematocrit\")\n",
    "    \n",
    "    for rule in hema_rules:\n",
    "        if hema >= rule.get('min') and hema < rule.get('max'):\n",
    "            hema_score = rule.get('points')\n",
    "            \n",
    "    return hema_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( hematocrit_score(25, CONFIG_FILE) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2K White Blood Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def wbc_score(wbc, config_file):\n",
    "    \"\"\" int, str -> int\n",
    "    age: The White Blood Count of the subject is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual \n",
    "    White Blood Count in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    wbc_rules = config.get(\"White Blood Count\")\n",
    "    \n",
    "    for rule in wbc_rules:\n",
    "        if wbc >= rule.get('min') and wbc < rule.get('max'):\n",
    "            wbc_score = rule.get('points')\n",
    "            \n",
    "    return wbc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( wbc_score(2, CONFIG_FILE) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2d-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #2L FiO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fio2_score(fio2, aag, pao2, config_file):\n",
    "    \"\"\" int, int, int, str -> int\n",
    "    fio2: The FiO2 pecentage is an integer value\n",
    "    aag: The A-a gradient is an integer value\n",
    "    pao2: The PaO2 is an integer value\n",
    "    config_file: The name of a configuration file to use for scoring\n",
    "    \n",
    "    The function should return a score for this subject based on where their actual FiO2 percentage,\n",
    "    A-a gradient and PaO2 in the scoring rules.\n",
    "    \"\"\"\n",
    "    config = json.load(open(config_file))\n",
    "    fio2_rules = config.get(\"FiO2\")\n",
    "    aag_rules = fio2_rules.get(\"A-a Gradient\")\n",
    "    pao2_rules = fio2_rules.get(\"PaO2\")\n",
    "    fio2_score = 0\n",
    "    if fio2 >= 0 and fio2 < 50:\n",
    "         for rule1 in pao2_rules:\n",
    "            if pao2 >= rule1.get('min') and pao2 < rule1.get('max'):\n",
    "                fio2_score = rule1.get('points')\n",
    "    if fio2 > 50 and fio2 <= 100:\n",
    "        for rule2 in aag_rules:\n",
    "            if aag >= rule2.get('min') and aag < rule2.get('max'):\n",
    "                fio2_score = rule2.get('points')\n",
    "    \n",
    "    return fio2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(fio2_score(70, 268, 65, CONFIG_FILE) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fio2_score(70, 300, 65, CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing you Functions\n",
    "\n",
    "Write enough test cases to verify that your functions work for evaulating all of the scoring inputs.  Have at least 3 test cases for each input.\n",
    "\n",
    "These tests can be written the same as the assertions we've use in previous assignments.  For example, if you a function for `temperature_score` then you write a test case like:\n",
    "\n",
    "```\n",
    "assert( temperature_score(37) == 0 )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( organ_history_score('Emergency', CONFIG_FILE) == 5)\n",
    "assert( age_score(30, CONFIG_FILE) == 0)\n",
    "assert( temperature_score(37, CONFIG_FILE) == 0)\n",
    "assert( ph_score(6.5, CONFIG_FILE) == 4)\n",
    "assert( hr_score(50, CONFIG_FILE) == 3)\n",
    "assert( rr_score(30, CONFIG_FILE) == 1)\n",
    "assert( sodium_score(100, CONFIG_FILE) == 4)\n",
    "assert( potassium_score(2.8, CONFIG_FILE) == 2)\n",
    "assert(creatinine_score(\"Acute Renal Failure\", 3, CONFIG_FILE) == 6)\n",
    "assert( hematocrit_score(25, CONFIG_FILE) == 2)\n",
    "assert( wbc_score(2, CONFIG_FILE) == 2)\n",
    "assert(fio2_score(70, 300, 65, CONFIG_FILE) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Put it all together\n",
    "\n",
    "Create a new function called `apache_score()` that takes all of the necessary inputs and returns the final Apache II score.  Use any variable names that you want.  For clarity and organization, my recommendation is to create them in the same order as they're documented in the website.\n",
    "\n",
    "1. Organ Failure History\n",
    "2. Age\n",
    "3. Temperature\n",
    "4. pH \n",
    "5. Heart rate\n",
    "6. Respiratory rate\n",
    "7. Sodium\n",
    "8. Potassium\n",
    "9. Creatinine\n",
    "10. Acute renal failure\n",
    "11. Hematocrit\n",
    "12. White Blood Count\n",
    "13. Glasgow Coma Scale\n",
    "14. FiO2\n",
    "15. PaO2\n",
    "16. A-a gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apache_score(history,age,temp,ph,hr,rr,sodium,potassium,failure_type,creatinine,hema,wbc,fio2,aag,pao2,gcs):\n",
    "    \n",
    "    # This function is a sumation of all the score.\n",
    "    total_score = 0\n",
    "    config_file = \"apache.json\"\n",
    "    total_score += organ_history_score(history, config_file)\n",
    "    total_score += age_score(age, config_file)\n",
    "    total_score += temperature_score(temp, config_file)\n",
    "    total_score += ph_score(ph, config_file)\n",
    "    total_score += hr_score(hr, config_file)\n",
    "    total_score += rr_score(rr, config_file)\n",
    "    total_score += sodium_score(sodium, config_file)\n",
    "    total_score += potassium_score(potassium, config_file)\n",
    "    total_score += creatinine_score(failure_type, creatinine, config_file)\n",
    "    total_score += hematocrit_score(hema, config_file)\n",
    "    total_score += wbc_score(wbc, config_file)\n",
    "    total_score += fio2_score(fio2, aag, pao2, config_file)\n",
    "    total_score += (15-gcs)\n",
    "    \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your Function\n",
    "\n",
    "Write a few test cases to make sure that your code functions correctly.  In the last step, you'll have LOTS of test cases run through, but you should do some of your before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_score('Emergency',6,27,7.3,174,10,170,7.8,\"Chronic Renal Failure\", 3,28,2,61, 458, 59,13) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Accessing and processing the patient file\n",
    "\n",
    "Fill out the simple function below to retrieve the patient data as a CSV file from any given URL and return a list of all of the Apache II scores based on the data you find for those patients.\n",
    "* The patient file will be a CSV\n",
    "* It will have column headers that match the labels shown above\n",
    "* The columns will not necessarily appear in the order shown above\n",
    "* You should output only the Apache II scores, not any other information\n",
    "* Your output should be a list in the same order as the input rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing your Function\n",
    "\n",
    "The URL for the test data is: https://hds5210-2020.s3.amazonaws.com/TestPatients.csv\n",
    "\n",
    "\n",
    "You can verify your results by comparing them against this data: https://hds5210-2020.s3.amazonaws.com/Scores.csv\n",
    "\n",
    "**CORRECTION ADDED 3/29** - If you calculated the Glasgow Coma Scale points as per the actual instructions in MDCalc, then please use this set of corrected scores to compare your results with: https://hds5210-2020.s3.amazonaws.com/Scores_corrected.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.0, 31.0, 47.0, 34.0, 44.0, 35.0, 31.0, 49.0, 40.0, 48.0, 42.0, 43.0, 32.0, 41.0, 42.0, 49.0, 37.0, 37.0, 38.0, 43.0, 41.0, 31.0, 38.0, 30.0, 41.0, 41.0, 34.0, 46.0, 40.0, 47.0, 36.0, 43.0, 41.0, 46.0, 44.0, 40.0, 39.0, 37.0, 41.0, 30.0, 46.0, 30.0, 41.0, 44.0, 35.0, 36.0, 40.0, 40.0, 30.0, 50.0, 52.0, 43.0, 46.0, 34.0, 33.0, 42.0, 41.0, 31.0, 46.0, 46.0, 34.0, 36.0, 33.0, 38.0, 26.0, 29.0, 46.0, 25.0, 40.0, 38.0, 39.0, 34.0, 39.0, 53.0, 44.0, 49.0, 37.0, 36.0, 36.0, 51.0, 33.0, 36.0, 43.0, 41.0, 24.0, 50.0, 29.0, 40.0, 36.0, 50.0, 29.0, 37.0, 34.0, 45.0, 34.0, 40.0, 37.0, 37.0, 47.0, 31.0, 33.0, 50.0, 28.0, 37.0, 33.0, 44.0, 40.0, 38.0, 40.0, 31.0, 44.0, 37.0, 44.0, 47.0, 25.0, 34.0, 32.0, 41.0, 38.0, 34.0, 38.0, 39.0, 41.0, 34.0, 29.0, 44.0, 22.0, 40.0, 34.0, 43.0, 40.0, 31.0, 35.0, 33.0, 27.0, 44.0, 52.0, 40.0, 53.0, 40.0, 40.0, 48.0, 31.0, 38.0, 49.0, 43.0, 35.0, 31.0, 36.0, 40.0, 34.0, 31.0, 30.0, 28.0, 38.0, 47.0, 32.0, 47.0, 31.0, 41.0, 40.0, 33.0, 35.0, 42.0, 49.0, 55.0, 51.0, 37.0, 53.0, 29.0, 33.0, 46.0, 36.0, 32.0, 31.0, 33.0, 42.0, 32.0, 41.0, 35.0, 39.0, 40.0, 40.0, 35.0, 28.0, 33.0, 42.0, 29.0, 30.0, 39.0, 34.0, 46.0, 30.0, 37.0, 31.0, 37.0, 41.0, 47.0, 45.0, 29.0, 45.0, 33.0, 33.0, 38.0, 28.0, 42.0, 32.0, 45.0, 36.0, 39.0, 43.0, 32.0, 37.0, 43.0, 34.0, 40.0, 27.0, 24.0, 39.0, 39.0, 35.0, 36.0, 39.0, 47.0, 27.0, 28.0, 50.0, 53.0, 36.0, 44.0, 38.0, 51.0, 43.0, 38.0, 38.0, 36.0, 40.0, 36.0, 40.0, 31.0, 39.0, 37.0, 38.0, 46.0, 28.0, 32.0, 37.0, 29.0, 26.0, 25.0, 52.0, 36.0, 24.0, 28.0, 30.0, 35.0, 45.0, 41.0, 41.0, 31.0, 45.0, 53.0, 45.0, 27.0, 34.0, 32.0, 31.0, 30.0, 33.0, 32.0, 30.0, 50.0, 37.0, 35.0, 55.0, 38.0, 23.0, 36.0, 22.0, 24.0, 28.0, 25.0, 33.0, 58.0, 31.0, 47.0, 43.0, 49.0, 32.0, 44.0, 46.0, 29.0, 30.0, 40.0, 46.0, 40.0, 44.0, 33.0, 43.0, 36.0, 36.0, 46.0, 44.0, 45.0, 46.0, 45.0, 41.0, 44.0, 36.0, 61.0, 50.0, 36.0, 36.0, 29.0, 40.0, 38.0, 31.0, 37.0, 52.0, 34.0, 38.0, 21.0, 36.0, 43.0, 33.0, 18.0, 31.0, 30.0, 49.0, 46.0, 45.0, 43.0, 44.0, 45.0]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('TestPatients.csv') as f:\n",
    "    patients = csv.reader(f)\n",
    "    next(patients,None)\n",
    "    my_scores = []\n",
    "    for patient in patients:\n",
    "        history = patient[1]\n",
    "        age = int(patient[2])\n",
    "        temp = int(patient[3])\n",
    "        ph = float(patient[4])\n",
    "        hr = int(patient[5])\n",
    "        rr = int(patient[6])\n",
    "        sodium = int(patient[7])\n",
    "        potassium = float(patient[8])\n",
    "        creatinine = float(patient[9])\n",
    "        failure_type = patient[10]\n",
    "        hema = int(patient[11])\n",
    "        wbc = int(patient[12])\n",
    "        gcs = int(patient[13])\n",
    "        fio2 = int(patient[14])\n",
    "        pao2 = int(patient[15])\n",
    "        aag = int(patient[16])\n",
    "        total_score = float(apache_score(history,age,temp,ph,hr,rr,sodium,potassium,failure_type,creatinine,hema,wbc,fio2,aag,pao2,gcs))\n",
    "        my_scores.append(total_score)\n",
    "print(my_scores)\n",
    "\n",
    "# (my_scores) is the list of scores based on my approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.0, 31.0, 47.0, 34.0, 44.0, 35.0, 31.0, 49.0, 40.0, 48.0, 42.0, 43.0, 32.0, 41.0, 42.0, 49.0, 37.0, 37.0, 38.0, 43.0, 41.0, 31.0, 38.0, 30.0, 41.0, 41.0, 34.0, 46.0, 40.0, 47.0, 36.0, 43.0, 41.0, 46.0, 44.0, 40.0, 39.0, 37.0, 41.0, 30.0, 46.0, 30.0, 41.0, 44.0, 35.0, 36.0, 40.0, 40.0, 30.0, 50.0, 52.0, 43.0, 46.0, 34.0, 33.0, 42.0, 41.0, 31.0, 46.0, 46.0, 34.0, 36.0, 33.0, 38.0, 26.0, 29.0, 46.0, 25.0, 40.0, 38.0, 39.0, 34.0, 39.0, 53.0, 44.0, 49.0, 37.0, 36.0, 36.0, 51.0, 33.0, 36.0, 43.0, 41.0, 24.0, 50.0, 29.0, 40.0, 36.0, 50.0, 29.0, 37.0, 34.0, 45.0, 34.0, 40.0, 37.0, 37.0, 47.0, 31.0, 33.0, 50.0, 28.0, 37.0, 33.0, 44.0, 40.0, 38.0, 40.0, 31.0, 44.0, 37.0, 44.0, 47.0, 25.0, 34.0, 32.0, 41.0, 38.0, 34.0, 38.0, 39.0, 41.0, 34.0, 29.0, 44.0, 22.0, 40.0, 34.0, 43.0, 40.0, 31.0, 35.0, 33.0, 27.0, 44.0, 52.0, 40.0, 53.0, 40.0, 40.0, 48.0, 31.0, 42.0, 49.0, 43.0, 35.0, 31.0, 36.0, 42.0, 34.0, 31.0, 30.0, 28.0, 38.0, 47.0, 32.0, 47.0, 31.0, 41.0, 40.0, 33.0, 35.0, 42.0, 49.0, 55.0, 51.0, 37.0, 53.0, 29.0, 33.0, 46.0, 36.0, 32.0, 33.0, 33.0, 42.0, 32.0, 41.0, 35.0, 39.0, 40.0, 40.0, 35.0, 28.0, 33.0, 42.0, 29.0, 30.0, 39.0, 34.0, 46.0, 30.0, 37.0, 31.0, 37.0, 41.0, 47.0, 45.0, 29.0, 45.0, 33.0, 33.0, 38.0, 28.0, 42.0, 32.0, 45.0, 36.0, 39.0, 43.0, 32.0, 37.0, 43.0, 34.0, 40.0, 27.0, 24.0, 39.0, 39.0, 35.0, 36.0, 39.0, 47.0, 27.0, 28.0, 50.0, 53.0, 36.0, 44.0, 38.0, 51.0, 43.0, 38.0, 38.0, 36.0, 40.0, 36.0, 40.0, 31.0, 39.0, 37.0, 38.0, 46.0, 28.0, 32.0, 37.0, 29.0, 26.0, 25.0, 52.0, 36.0, 24.0, 28.0, 30.0, 35.0, 45.0, 41.0, 41.0, 31.0, 45.0, 53.0, 45.0, 31.0, 34.0, 32.0, 33.0, 30.0, 33.0, 32.0, 30.0, 50.0, 37.0, 35.0, 55.0, 38.0, 23.0, 36.0, 22.0, 24.0, 28.0, 25.0, 33.0, 58.0, 31.0, 47.0, 43.0, 49.0, 32.0, 44.0, 46.0, 29.0, 30.0, 40.0, 46.0, 40.0, 44.0, 33.0, 43.0, 36.0, 36.0, 46.0, 44.0, 45.0, 46.0, 45.0, 41.0, 44.0, 36.0, 61.0, 50.0, 36.0, 36.0, 29.0, 40.0, 38.0, 31.0, 37.0, 52.0, 34.0, 38.0, 21.0, 36.0, 43.0, 33.0, 18.0, 31.0, 30.0, 49.0, 46.0, 45.0, 43.0, 44.0, 45.0]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Scores_corrected.csv') as f:\n",
    "    corrected_scores = []\n",
    "    scores = csv.reader(f)\n",
    "    next(scores,None)\n",
    "    for line in scores:\n",
    "        corrected_scores.append(float(line[0]))\n",
    "    print(corrected_scores)\n",
    "\n",
    "# (corrected_scores) is the list of score read from \"Scores_corrected.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143, 149, 174, 263, 266]\n"
     ]
    }
   ],
   "source": [
    "loc_diff = []\n",
    "for loc in range(0,len(my_scores)):\n",
    "    if my_scores[loc] != corrected_scores[loc]:\n",
    "        loc_diff.append(loc)\n",
    "print(loc_diff)\n",
    "    \n",
    "# It seems there is only five of them uncorrect? \n",
    "# I think I am using the right approach. The accuracy is about 98.5% (329/334).\n",
    "# The (loc_diff) shows the location of the uncorrect ones in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
